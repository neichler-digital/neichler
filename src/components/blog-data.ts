// Auto-generated by scripts/generate-blog.ts
// Do not edit directly - edit markdown files in content/blog/ instead

// eslint-disable-next-line @typescript-eslint/no-explicit-any
export type HiccupNode = any;

export interface BlogPost {
  id: string;
  title: string;
  excerpt: string;
  date: string;
  author: string;
  color: string;
  content: HiccupNode[];
}

export const blogPosts: BlogPost[] = [
  {
    "id": "skia-bindings-jai",
    "title": "Automating the Art: Programmatically Generating Skia Bindings for Jai",
    "excerpt": "Connecting a high-performance compiled language like Jai to a massive C++ library like Google's Skia is usually a task synonymous with \"pain.\" Here's how we automated it.",
    "date": "2025-12-03",
    "author": "Timothy Eichler",
    "color": "var(--accent-magenta)",
    "content": [
      [
        "p",
        {},
        "Connecting a high-performance compiled language like Jai to a massive C++ library like Google's Skia (the graphics engine behind Chrome, Android, and Flutter) is usually a task synonymous with \"pain.\""
      ],
      [
        "p",
        {},
        [
          "strong",
          {},
          "Repository:"
        ],
        " ",
        [
          "a",
          {
            "href": "https://github.com/uncrumpled2/jai-skia",
            "target": "_blank",
            "rel": "noopener noreferrer"
          },
          "github.com/uncrumpled2/jai-skia"
        ]
      ],
      [
        "p",
        {},
        "Skia is huge. It makes heavy use of C++ specific features: inheritance, templates, smart pointers, and vtables. Writing bindings by hand for such a library isn't just tedious—it's a maintenance nightmare."
      ],
      [
        "p",
        {},
        "Instead of writing wrappers by hand, we used Jai's built-in metaprogramming capabilities to write a script that writes the code for us. Here is how we bridged the gap between Jai and Skia, and why it was worth it."
      ],
      [
        "h2",
        {},
        "The Tool: Bindings_Generator"
      ],
      [
        "p",
        {},
        "Jai ships with a module called Bindings_Generator. Unlike simple regex-based scripts people often write in Python, this tool is a heavyweight. It links against libclang, parses the actual C++ Abstract Syntax Tree (AST), and understands the deep structure of the types."
      ],
      [
        "p",
        {},
        "It maps C++ classes to Jai structs, calculates vtable layouts for virtual functions, handles enum conversions, and manages name mangling."
      ],
      [
        "h2",
        {},
        "The Process: How We Did It"
      ],
      [
        "p",
        {},
        "We created a generator script (generate.jai) that configures the binding options. Here is the concrete workflow we established:"
      ],
      [
        "h3",
        {},
        "1. The \"Wrapper\" Header"
      ],
      [
        "p",
        {},
        "We can't just point the generator at a folder. We created a wrapper.h file that acts as a single entry point, including the specific Skia headers we care about:"
      ],
      [
        "pre",
        {},
        [
          "code",
          {
            "class": "cpp"
          },
          "// wrapper.h\n#include \"include/core/SkCanvas.h\"\n#include \"include/core/SkSurface.h\"\n#include \"include/core/SkPaint.h\"\n#include \"include/encode/SkPngEncoder.h\"\n// ..."
        ]
      ],
      [
        "h3",
        {},
        "2. Mimicking the Compiler"
      ],
      [
        "p",
        {},
        "The hardest part of generating bindings is making libclang happy. If the parser can't find standard headers (like ",
        [
          "code",
          {},
          "<cmath>"
        ],
        " or ",
        [
          "code",
          {},
          "<stddef.h>"
        ],
        ") or doesn't know the architecture macros, it fails."
      ],
      [
        "p",
        {},
        "We had to aggressively configure the Generate_Bindings_Options to mimic a GCC build on Linux:"
      ],
      [
        "pre",
        {},
        [
          "code",
          {
            "class": "jai"
          },
          "array_add(*options.extra_clang_arguments, \"-x\", \"c++\", \"-std=c++17\");\narray_add(*options.extra_clang_arguments, \"-DSK_BUILD_FOR_UNIX\"); // Critical for Skia\n// We also manually added system include paths (/usr/include/...)\n// so Clang could find standard C++ headers."
        ]
      ],
      [
        "h3",
        {},
        "3. The \"Chicken and Egg\" Problem"
      ],
      [
        "p",
        {},
        "Usually, the generator wants to load the compiled library (libskia.so or .a) during generation. It does this to verify which symbols actually exist and strips out declarations that aren't in the binary."
      ],
      [
        "p",
        {},
        "However, we wanted a generator that could run before we dealt with the complex build process of Skia."
      ],
      [
        "p",
        {},
        [
          "strong",
          {},
          "The Fix:"
        ],
        " We set ",
        [
          "code",
          {},
          "options.strip_flags = 0"
        ],
        " to force the generator to output everything, regardless of whether the library was present. We then wrote a small post-processing routine in Jai to open the generated file and replace the placeholder ",
        [
          "code",
          {},
          "__UnknownLib"
        ],
        " with our library name ",
        [
          "code",
          {},
          "libskia"
        ],
        "."
      ],
      [
        "h3",
        {},
        "4. Automating the \"Gluing\""
      ],
      [
        "p",
        {},
        "Generating the raw bindings was only half the battle. The generated code contained C++ patterns that don't map 1:1 to Jai, requiring significant post-processing. We automated this entirely within ",
        [
          "code",
          {},
          "generate.jai"
        ],
        ":"
      ],
      [
        "ul",
        {},
        [
          "li",
          {},
          [
            "strong",
            {},
            "Operator Overloading:"
          ],
          " C++ ",
          [
            "code",
            {},
            "operator+="
          ],
          " became ",
          [
            "code",
            {},
            "operator_plus_equals"
          ],
          "."
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Template Emulation:"
          ],
          " We injected a robust ",
          [
            "code",
            {},
            "std"
          ],
          " struct definition to mock C++ ",
          [
            "code",
            {},
            "std::unique_ptr"
          ],
          ", ",
          [
            "code",
            {},
            "std::vector"
          ],
          ", ",
          [
            "code",
            {},
            "std::atomic"
          ],
          ", and ",
          [
            "code",
            {},
            "std::tuple"
          ],
          "."
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Missing Linkage:"
          ],
          " We automatically comment out static internal symbols (starting with ",
          [
            "code",
            {},
            "_ZL"
          ],
          ") that aren't exported by the shared library."
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Type Fixing:"
          ],
          " We corrected malformed struct definitions caused by complex C++ SFINAE templates (like ",
          [
            "code",
            {},
            "AutoTMalloc"
          ],
          ") and fixed enum types that were incorrectly identified as ",
          [
            "code",
            {},
            "bool"
          ],
          "."
        ]
      ],
      [
        "h2",
        {},
        "The Result: By the Numbers"
      ],
      [
        "p",
        {},
        "The output is a single file, skia_bindings.jai."
      ],
      [
        "ul",
        {},
        [
          "li",
          {},
          [
            "strong",
            {},
            "Functions Generated:"
          ],
          " ~1,954"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Structs/Classes Mapped:"
          ],
          " ~215"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Total Lines of Code:"
          ],
          " ~15,600+"
        ]
      ],
      [
        "h3",
        {},
        "The ROI (Return on Investment)"
      ],
      [
        "p",
        {},
        "If a developer were to manually write high-quality bindings (handling type conversion, vtables, and correct memory layouts), they might average 50 lines of correct code per hour."
      ],
      [
        "ul",
        {},
        [
          "li",
          {},
          [
            "strong",
            {},
            "Manual Estimate:"
          ],
          " ~300 hours (roughly 7.5 work weeks)"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Our Approach:"
          ],
          " ~1 hour of configuration and debugging"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Update Cost:"
          ],
          " ~10 seconds (running the script again when Skia updates)"
        ]
      ],
      [
        "p",
        {},
        "We now have a fully functional drawing API. We successfully created a raster surface, drew a rectangle, and encoded it to a PNG, all from Jai, calling into the optimized C++ Skia core."
      ],
      [
        "h2",
        {},
        "Trade-offs and Negatives"
      ],
      [
        "p",
        {},
        "It isn't all sunshine and rainbows. There are distinct trade-offs to this approach:"
      ],
      [
        "ol",
        {},
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "API Opaqueness:"
            ],
            " The generator creates \"Raw\" C-style structs. While it handles inheritance via composition (e.g., SkCanvas contains SkRefCnt), you lose the syntactic sugar of C++. You have to manually call ",
            [
              "code",
              {},
              "Destructor_Base"
            ],
            " instead of relying on a C++ smart pointer destructor."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Build System Friction:"
            ],
            " Generating the code is easy; linking it is hard. Skia uses its own build system (GN/Ninja). We still have to build Skia separately and ensure the binary matches the ABI expected by our generated code. We had to specifically build Skia as a shared component (",
            [
              "code",
              {},
              "is_component_build=true"
            ],
            ") to ensure symbols were exported."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Bloat:"
            ],
            " We generated 15,000 lines of code. We probably only need 5% of that for a simple application. This increases compilation time and noise in the namespace."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Inline Functions:"
            ],
            " Heavily optimized C++ libraries like Skia put a lot of logic in header-only inline functions. libclang sees these, but they aren't exported in the .so file. The generator often has to skip these (or we have to comment them out), meaning we lose some convenience methods (like 2-arg ",
            [
              "code",
              {},
              "SkImageInfo::MakeN32Premul"
            ],
            ") and have to use the more verbose raw structs."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "ABI Mismatches:"
            ],
            " Some C++ calling conventions don't translate cleanly through FFI. We discovered that passing ",
            [
              "code",
              {},
              "sk_sp<T>"
            ],
            " (Skia's smart pointer) ",
            [
              "strong",
              {},
              "by value"
            ],
            " from Jai to C++ corrupts the pointer. The Itanium C++ ABI passes single-pointer structs in registers, but Jai's FFI layer doesn't match this behavior exactly. This required writing wrapper functions to work around the issue."
          ]
        ]
      ],
      [
        "h2",
        {},
        "The sk_sp Problem (and Solution)"
      ],
      [
        "p",
        {},
        "After getting basic drawing working, we hit a wall trying to use custom fonts. Code like this would crash or produce garbage:"
      ],
      [
        "pre",
        {},
        [
          "code",
          {
            "class": "jai"
          },
          "// This looks correct but doesn't work!\ntypeface_sp := SkFontMgr.makeFromFile(fontmgr, \"DejaVuSans.ttf\", 0);\nSkFont.Constructor(*font, typeface_sp, 24.0);  // typeface_sp passed by value\n// Result: font.fTypeface.fPtr contains garbage"
        ]
      ],
      [
        "p",
        {},
        "The ",
        [
          "code",
          {},
          "sk_sp<SkTypeface>"
        ],
        " parameter was being corrupted during the FFI call. After debugging, we traced it to an ABI mismatch: the C++ side expected the pointer in a register (RSI), but Jai was passing it differently."
      ],
      [
        "h3",
        {},
        "The Fix: A Helper Library"
      ],
      [
        "p",
        {},
        "We couldn't just \"fix\" the FFI—that would require compiler changes. Instead, we wrote a small C++ helper library (",
        [
          "code",
          {},
          "skia_ref_helper.cpp"
        ],
        ") that exposes reference counting functions:"
      ],
      [
        "pre",
        {},
        [
          "code",
          {
            "class": "cpp"
          },
          "extern \"C\" {\n    void sk_ref_cnt_ref(void* ptr) {\n        if (ptr) {\n            int32_t* refcnt = reinterpret_cast<int32_t*>(static_cast<char*>(ptr) + 8);\n            __atomic_add_fetch(refcnt, 1, __ATOMIC_RELAXED);\n        }\n    }\n    void sk_ref_cnt_unref(void* ptr) { /* ... calls destructor when count hits 0 */ }\n}"
        ]
      ],
      [
        "p",
        {},
        "This is necessary because ",
        [
          "code",
          {},
          "SkRefCntBase::ref()"
        ],
        " and ",
        [
          "code",
          {},
          "unref()"
        ],
        " are inlined in Skia's headers and not exported from ",
        [
          "code",
          {},
          "libskia.so"
        ],
        "."
      ],
      [
        "h3",
        {},
        "Safe Wrappers"
      ],
      [
        "p",
        {},
        "With reference counting available, we added safe wrapper functions to the generated bindings that bypass the problematic by-value ",
        [
          "code",
          {},
          "sk_sp"
        ],
        " parameters:"
      ],
      [
        "pre",
        {},
        [
          "code",
          {
            "class": "jai"
          },
          "SkFont_make :: (typeface: *SkTypeface, size: SkScalar) -> SkFont {\n    font: SkFont;\n    SkFont.Constructor(*font);  // Default constructor (no sk_sp parameter)\n    SkFont.setSize(*font, size);\n    // Manually set the typeface pointer and manage refcount\n    if typeface then sk_ref_cnt_ref(typeface);\n    font.fTypeface.fPtr = typeface;\n    return font;\n}"
        ]
      ],
      [
        "p",
        {},
        "Now custom fonts work correctly:"
      ],
      [
        "pre",
        {},
        [
          "code",
          {
            "class": "jai"
          },
          "sp_fontmgr := SkFontMgr_New_Custom_Directory(\"/usr/share/fonts/truetype/dejavu\");\nsp_typeface := SkFontMgr.makeFromFile(sp_fontmgr.fPtr, \"DejaVuSans.ttf\", 0);\nfont := SkFont_make(sp_typeface.fPtr, 24.0);  // Works!\nSkCanvas.drawSimpleText(canvas, \"Hello!\", 6, .kUTF8, 100, 100, font, paint);"
        ]
      ],
      [
        "p",
        {},
        "This pattern—identifying FFI edge cases and writing targeted workarounds—is likely to recur with any large C++ library. The key insight is that automated bindings get you 95% of the way there; the remaining 5% requires understanding the underlying ABI."
      ],
      [
        "h2",
        {},
        "Summary"
      ],
      [
        "p",
        {},
        "Despite the friction of C++ build systems, the ability to programmatically generate 15,000 lines of bindings in seconds is a superpower. It turns a multi-month porting project into an afternoon task, allowing us to use industry-standard graphics libraries in a modern language immediately."
      ]
    ]
  },
  {
    "id": "ai-performance-programming",
    "title": "Lessons from AI-Assisted Performance Programming",
    "excerpt": "We conducted an experiment to understand how AI approaches the 1 Billion Row Challenge across multiple programming languages, using three different prompting strategies.",
    "date": "2025-11-30",
    "author": "Timothy Eichler",
    "color": "var(--accent-green)",
    "content": [
      [
        "h2",
        {},
        "Overview"
      ],
      [
        "p",
        {},
        "We conducted an experiment to understand how AI (Claude) approaches the 1 Billion Row Challenge across multiple programming languages, using three different prompting strategies:"
      ],
      [
        "ol",
        {},
        [
          "li",
          {},
          [
            "strong",
            {},
            "Normal"
          ],
          ": \"Solve the challenge with clean, idiomatic code. Focus on correctness and readability.\" (No mention of performance)"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Performant"
          ],
          ": \"Solve the challenge with a strong focus on performance. Use all available optimization techniques.\""
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Performance-Aware"
          ],
          ": \"Apply performance-aware programming principles from a detailed guide covering the five performance multipliers\""
        ]
      ],
      [
        "p",
        {},
        "The goal was to extract lessons for effectively collaborating with AI on performance-critical code."
      ],
      [
        "h2",
        {},
        "Results Summary"
      ],
      [
        "p",
        {},
        "Here are the complete benchmark results across all languages and variants:"
      ],
      [
        "table",
        {},
        [
          "thead",
          {},
          [
            "tr",
            {},
            [
              "th",
              {},
              "Language"
            ],
            [
              "th",
              {},
              "Normal"
            ],
            [
              "th",
              {},
              "Performant"
            ],
            [
              "th",
              {},
              "Performance-Aware"
            ]
          ]
        ],
        [
          "tbody",
          {},
          [
            "tr",
            {},
            [
              "td",
              {},
              "Zig"
            ],
            [
              "td",
              {},
              "133s"
            ],
            [
              "td",
              {},
              "7.5s"
            ],
            [
              "td",
              {},
              "7.3s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "C"
            ],
            [
              "td",
              {},
              "773s"
            ],
            [
              "td",
              {},
              "6.8s"
            ],
            [
              "td",
              {},
              "24.5s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Nim"
            ],
            [
              "td",
              {},
              "208s"
            ],
            [
              "td",
              {},
              "8.3s"
            ],
            [
              "td",
              {},
              "7.8s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Rust"
            ],
            [
              "td",
              {},
              "190s"
            ],
            [
              "td",
              {},
              "8.9s"
            ],
            [
              "td",
              {},
              "8.3s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Java"
            ],
            [
              "td",
              {},
              "168s"
            ],
            [
              "td",
              {},
              "10.6s"
            ],
            [
              "td",
              {},
              "9.3s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "OCaml"
            ],
            [
              "td",
              {},
              "248s"
            ],
            [
              "td",
              {},
              "21.8s"
            ],
            [
              "td",
              {},
              "15.8s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Clojure"
            ],
            [
              "td",
              {},
              "~12,480s"
            ],
            [
              "td",
              {},
              "17.7s"
            ],
            [
              "td",
              {},
              "20.8s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Jai"
            ],
            [
              "td",
              {},
              "110s"
            ],
            [
              "td",
              {},
              "53.0s"
            ],
            [
              "td",
              {},
              "70.4s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Red"
            ],
            [
              "td",
              {},
              "~15,800s"
            ],
            [
              "td",
              {},
              "~6,990s"
            ],
            [
              "td",
              {},
              "~13,740s"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Baseline (gonix)"
            ],
            [
              "td",
              {},
              "-"
            ],
            [
              "td",
              {},
              "7.8s"
            ],
            [
              "td",
              {},
              "-"
            ]
          ]
        ]
      ],
      [
        "p",
        {},
        "Note: Red and Clojure normal times are extrapolated from 100k row samples due to extremely slow interpreted execution."
      ],
      [
        "h2",
        {},
        "Key Findings"
      ],
      [
        "h3",
        {},
        "If You Don't Ask for Performance, You Won't Get It"
      ],
      [
        "p",
        {},
        "The difference between \"normal\" and \"performant\" prompts is stark:"
      ],
      [
        "table",
        {},
        [
          "thead",
          {},
          [
            "tr",
            {},
            [
              "th",
              {},
              "Language"
            ],
            [
              "th",
              {},
              "Normal"
            ],
            [
              "th",
              {},
              "Performant"
            ],
            [
              "th",
              {},
              "Speedup"
            ]
          ]
        ],
        [
          "tbody",
          {},
          [
            "tr",
            {},
            [
              "td",
              {},
              "Jai"
            ],
            [
              "td",
              {},
              "110s"
            ],
            [
              "td",
              {},
              "53s"
            ],
            [
              "td",
              {},
              "2x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Zig"
            ],
            [
              "td",
              {},
              "133s"
            ],
            [
              "td",
              {},
              "7.5s"
            ],
            [
              "td",
              {},
              "18x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Java"
            ],
            [
              "td",
              {},
              "168s"
            ],
            [
              "td",
              {},
              "10.6s"
            ],
            [
              "td",
              {},
              "16x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Rust"
            ],
            [
              "td",
              {},
              "190s"
            ],
            [
              "td",
              {},
              "8.9s"
            ],
            [
              "td",
              {},
              "21x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Nim"
            ],
            [
              "td",
              {},
              "208s"
            ],
            [
              "td",
              {},
              "8.3s"
            ],
            [
              "td",
              {},
              "25x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "OCaml"
            ],
            [
              "td",
              {},
              "248s"
            ],
            [
              "td",
              {},
              "21.8s"
            ],
            [
              "td",
              {},
              "11x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "C"
            ],
            [
              "td",
              {},
              "773s"
            ],
            [
              "td",
              {},
              "6.8s"
            ],
            [
              "td",
              {},
              "114x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Clojure"
            ],
            [
              "td",
              {},
              "~12,480s"
            ],
            [
              "td",
              {},
              "17.7s"
            ],
            [
              "td",
              {},
              "~705x"
            ]
          ]
        ]
      ],
      [
        "p",
        {},
        "The normal solutions are perfectly correct and readable, but they're 2-700x slower. The AI produced clean, idiomatic code when asked - but didn't volunteer optimizations unless explicitly requested."
      ],
      [
        "h3",
        {},
        "Two Approaches, Similar Results"
      ],
      [
        "p",
        {},
        "The \"performant\" and \"performance-aware\" prompts represent two different strategies:"
      ],
      [
        "ul",
        {},
        [
          "li",
          {},
          [
            "strong",
            {},
            "Performant"
          ],
          ": Tell the AI to optimize aggressively, let it figure out how"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Performance-Aware"
          ],
          ": Provide a detailed guide explaining the five performance multipliers: reduce waste, maximize IPC, SIMD, cache optimization, and multithreading"
        ]
      ],
      [
        "table",
        {},
        [
          "thead",
          {},
          [
            "tr",
            {},
            [
              "th",
              {},
              "Language"
            ],
            [
              "th",
              {},
              "Performant"
            ],
            [
              "th",
              {},
              "Perf-Aware"
            ],
            [
              "th",
              {},
              "Difference"
            ]
          ]
        ],
        [
          "tbody",
          {},
          [
            "tr",
            {},
            [
              "td",
              {},
              "C"
            ],
            [
              "td",
              {},
              "6.8s"
            ],
            [
              "td",
              {},
              "24.5s"
            ],
            [
              "td",
              {},
              "-262% (worse)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Zig"
            ],
            [
              "td",
              {},
              "7.5s"
            ],
            [
              "td",
              {},
              "7.3s"
            ],
            [
              "td",
              {},
              "+3% better"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Nim"
            ],
            [
              "td",
              {},
              "8.3s"
            ],
            [
              "td",
              {},
              "7.8s"
            ],
            [
              "td",
              {},
              "+6% better"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Rust"
            ],
            [
              "td",
              {},
              "8.9s"
            ],
            [
              "td",
              {},
              "8.3s"
            ],
            [
              "td",
              {},
              "+7% better"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Java"
            ],
            [
              "td",
              {},
              "10.6s"
            ],
            [
              "td",
              {},
              "9.3s"
            ],
            [
              "td",
              {},
              "+12% better"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "OCaml"
            ],
            [
              "td",
              {},
              "21.8s"
            ],
            [
              "td",
              {},
              "15.8s"
            ],
            [
              "td",
              {},
              "+28% better"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Clojure"
            ],
            [
              "td",
              {},
              "17.7s"
            ],
            [
              "td",
              {},
              "20.8s"
            ],
            [
              "td",
              {},
              "-18% (worse)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Jai"
            ],
            [
              "td",
              {},
              "53.0s"
            ],
            [
              "td",
              {},
              "70.4s"
            ],
            [
              "td",
              {},
              "-33% (worse)"
            ]
          ]
        ]
      ],
      [
        "p",
        {},
        "The results are mixed. For most languages, the performance-aware approach produced slightly faster code (7-28% improvement). However, for C, Clojure, and Jai, the \"just optimize\" approach actually outperformed the guided approach."
      ],
      [
        "p",
        {},
        "Baseline comparison: The gonix unsafe Java entry (11th place in the official competition at 2.5s, selected because it didn't use GraalVM) ran on our system in 7.8s. Our best AI-generated solutions (C at 6.8s, Zig at 7.3s, Nim at 7.8s) achieved competitive or better performance."
      ],
      [
        "h3",
        {},
        "The Code Complexity Tax"
      ],
      [
        "p",
        {},
        "Performance comes at a cost in code complexity:"
      ],
      [
        "table",
        {},
        [
          "thead",
          {},
          [
            "tr",
            {},
            [
              "th",
              {},
              "Language"
            ],
            [
              "th",
              {},
              "Normal"
            ],
            [
              "th",
              {},
              "Performant"
            ],
            [
              "th",
              {},
              "Performance-Aware"
            ]
          ]
        ],
        [
          "tbody",
          {},
          [
            "tr",
            {},
            [
              "td",
              {},
              "Rust"
            ],
            [
              "td",
              {},
              "104"
            ],
            [
              "td",
              {},
              "330 (3.2x)"
            ],
            [
              "td",
              {},
              "359 (3.5x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "C"
            ],
            [
              "td",
              {},
              "123"
            ],
            [
              "td",
              {},
              "304 (2.5x)"
            ],
            [
              "td",
              {},
              "355 (2.9x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Java"
            ],
            [
              "td",
              {},
              "71"
            ],
            [
              "td",
              {},
              "276 (3.9x)"
            ],
            [
              "td",
              {},
              "318 (4.5x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Zig"
            ],
            [
              "td",
              {},
              "123"
            ],
            [
              "td",
              {},
              "323 (2.6x)"
            ],
            [
              "td",
              {},
              "355 (2.9x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Nim"
            ],
            [
              "td",
              {},
              "64"
            ],
            [
              "td",
              {},
              "253 (4.0x)"
            ],
            [
              "td",
              {},
              "257 (4.0x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "OCaml"
            ],
            [
              "td",
              {},
              "88"
            ],
            [
              "td",
              {},
              "264 (3.0x)"
            ],
            [
              "td",
              {},
              "316 (3.6x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Clojure"
            ],
            [
              "td",
              {},
              "61"
            ],
            [
              "td",
              {},
              "200 (3.3x)"
            ],
            [
              "td",
              {},
              "252 (4.1x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Jai"
            ],
            [
              "td",
              {},
              "260"
            ],
            [
              "td",
              {},
              "337 (1.3x)"
            ],
            [
              "td",
              {},
              "417 (1.6x)"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Red"
            ],
            [
              "td",
              {},
              "85"
            ],
            [
              "td",
              {},
              "83 (1.0x)"
            ],
            [
              "td",
              {},
              "153 (1.8x)"
            ]
          ]
        ]
      ],
      [
        "p",
        {},
        "Average lines of code across all languages:"
      ],
      [
        "table",
        {},
        [
          "thead",
          {},
          [
            "tr",
            {},
            [
              "th",
              {},
              "Variant"
            ],
            [
              "th",
              {},
              "Avg LOC"
            ],
            [
              "th",
              {},
              "Increase from Normal"
            ]
          ]
        ],
        [
          "tbody",
          {},
          [
            "tr",
            {},
            [
              "td",
              {},
              "Normal"
            ],
            [
              "td",
              {},
              "109"
            ],
            [
              "td",
              {},
              "-"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Performant"
            ],
            [
              "td",
              {},
              "262"
            ],
            [
              "td",
              {},
              "2.4x"
            ]
          ],
          [
            "tr",
            {},
            [
              "td",
              {},
              "Performance-Aware"
            ],
            [
              "td",
              {},
              "297"
            ],
            [
              "td",
              {},
              "2.7x"
            ]
          ]
        ]
      ],
      [
        "p",
        {},
        "The biggest code explosions happened in Java (71 → 318 lines, 4.5x) and Clojure (61 → 252 lines, 4.1x). Jai had the smallest relative increase (1.6x), but it started with the largest normal solution (260 lines) due to the AI struggling with the less-documented language."
      ],
      [
        "h2",
        {},
        "Common Optimization Patterns"
      ],
      [
        "p",
        {},
        "Across all languages, the AI consistently applied these optimizations when asked for performance:"
      ],
      [
        "ol",
        {},
        [
          "li",
          {},
          [
            "strong",
            {},
            "Memory-mapped I/O"
          ],
          ": Every performant solution used mmap instead of buffered reads"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Parallel processing"
          ],
          ": All solutions divided work across CPU cores"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Integer arithmetic"
          ],
          ": Temperature stored as int×10 to avoid floating-point operations"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Custom hash tables"
          ],
          ": Most solutions implemented open-addressing with FNV-1a hashing"
        ],
        [
          "li",
          {},
          [
            "strong",
            {},
            "Per-thread accumulators"
          ],
          ": Each thread maintains its own hash table, merged at the end"
        ]
      ],
      [
        "h2",
        {},
        "Hands-Off After Setup"
      ],
      [
        "p",
        {},
        "An interesting observation: after the initial implementation work, the AI was fully hands-off. Even when the AI noted in its progress logs that \"more work could be done to improve the solution\" (see C performance-aware noting it was slower than the performant version), it stopped when the validation passed. The AI follows instructions literally - if you want it to keep optimizing, you need to tell it to."
      ],
      [
        "h2",
        {},
        "Lessons Learned"
      ],
      [
        "ol",
        {},
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Be explicit about performance requirements."
            ],
            " \"Make it fast\" produces vastly different code than \"make it clean.\" If you want performance, ask for it upfront."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Detailed guidance can help, but isn't magic."
            ],
            " The performance-aware guide helped in some languages (OCaml saw 28% improvement) but hurt in others (C was 262% worse). The AI's innate optimization knowledge often matched or exceeded what a guide could provide."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Expect 2-4x more code for optimized solutions."
            ],
            " Performance-critical code is inherently more complex - more explicit memory management, parallel coordination, and low-level operations."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "AI follows instructions, not intent."
            ],
            " If you want the AI to iterate and improve, explicitly request iterations. \"Validate and stop\" is the default behavior."
          ]
        ],
        [
          "li",
          {},
          [
            "p",
            {},
            [
              "strong",
              {},
              "Language familiarity matters."
            ],
            " The AI produced better optimizations in languages with more training data (Rust, Java, C) versus niche languages (Jai, Red)."
          ]
        ]
      ],
      [
        "h2",
        {},
        "Methodology Notes"
      ],
      [
        "ul",
        {},
        [
          "li",
          {},
          "All benchmarks run on the same system (Linux, 16 cores, WSL2)"
        ],
        [
          "li",
          {},
          "13GB input file with 1 billion rows"
        ],
        [
          "li",
          {},
          "Baseline: gonix unsafe java solution (7.8s on our system, 2.5s in official competition at 11th place)"
        ],
        [
          "li",
          {},
          "Each solution was developed independently - no cross-pollination between variants"
        ],
        [
          "li",
          {},
          "AI was hands-off after initial work, no manual intervention"
        ]
      ]
    ]
  },
  {
    "id": "automating-claude",
    "title": "Automating Claude",
    "excerpt": "With AI tools getting more and more capable for coding, the dream of working like Homer is becoming more of a reality.",
    "date": "2025-11-27",
    "author": "Timothy Eichler",
    "color": "var(--accent-cyan)",
    "content": [
      [
        "p",
        {},
        "With AI tools getting more and more capable for coding, the dream of working like Homer is becoming more of a reality. Instead of having a bird cover for us (see the video: ",
        [
          "a",
          {
            "href": "https://www.youtube.com/shorts/PPk-z5ZJcrA",
            "target": "_blank",
            "rel": "noopener noreferrer"
          },
          "https://www.youtube.com/shorts/PPk-z5ZJcrA"
        ],
        "), we have created automate_claude."
      ],
      [
        "p",
        {},
        "The magic first starts with breaking down your tasks into iterative Claude commands. Once this is done, one would normally have to enter them in and wait for them to execute. Automate Claude takes over this task for us - we can enter in the command sequence that we want it to execute, and it will take care to run the sequence of commands N times (whatever we decide)."
      ],
      [
        "p",
        {},
        "In order to make sure work was completed properly, we run a check after each command and optionally retry if something went wrong. If we run out of usage and are throttled, the program will sleep until it can continue working again."
      ],
      [
        "p",
        {},
        "Note: in case you didn't know, each time we interact with a chat agent, the entire history of that chat session is sent to the model for computation, meaning we run our limits down faster. The automate command makes sure to run each command in a fresh session for us as well."
      ],
      [
        "p",
        {},
        "The command currently only runs on Linux but we would be open to updating it to other platforms if people are interested."
      ],
      [
        "p",
        {},
        "Check out the repo: ",
        [
          "a",
          {
            "href": "https://github.com/neichler-digital/automate-claude",
            "target": "_blank",
            "rel": "noopener noreferrer"
          },
          "https://github.com/neichler-digital/automate-claude"
        ]
      ]
    ]
  }
];
